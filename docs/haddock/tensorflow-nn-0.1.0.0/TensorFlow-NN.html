<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>TensorFlow.NN</title><link href="ocean.css" rel="stylesheet" type="text/css" title="Ocean" /><script src="haddock-util.js" type="text/javascript"></script><script type="text/javascript">//<![CDATA[
window.onload = function () {pageLoad();setSynopsis("mini_TensorFlow-NN.html");};
//]]>
</script></head><body><div id="package-header"><ul class="links" id="page-menu"><li><a href="index.html">Contents</a></li><li><a href="doc-index.html">Index</a></li></ul><p class="caption">tensorflow-nn-0.1.0.0: Friendly layer around TensorFlow bindings.</p></div><div id="content"><div id="module-header"><table class="info"><tr><th>Safe Haskell</th><td>None</td></tr><tr><th>Language</th><td>Haskell2010</td></tr></table><p class="caption">TensorFlow.NN</p></div><div id="synopsis"><p id="control.syn" class="caption expander" onclick="toggleSection('syn')">Synopsis</p><ul id="section.syn" class="hide" onclick="toggleSection('syn')"><li class="src short"><a href="#v:sigmoidCrossEntropyWithLogits">sigmoidCrossEntropyWithLogits</a> :: (<a href="../tensorflow-0.1.0.0/TensorFlow-Build.html#t:MonadBuild">MonadBuild</a> m, <a href="../tensorflow-0.1.0.0/TensorFlow-Types.html#t:OneOf">OneOf</a> `[<a href="../base-4.8.2.0/Prelude.html#t:Float">Float</a>, <a href="../base-4.8.2.0/Prelude.html#t:Double">Double</a>]` a, <a href="../tensorflow-0.1.0.0/TensorFlow-Types.html#t:TensorType">TensorType</a> a, <a href="../base-4.8.2.0/Prelude.html#t:Num">Num</a> a) =&gt; <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Tensor">Tensor</a> <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Value">Value</a> a -&gt; <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Tensor">Tensor</a> <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Value">Value</a> a -&gt; m (<a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Tensor">Tensor</a> <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Value">Value</a> a)</li></ul></div><div id="interface"><h1>Documentation</h1><div class="top"><p class="src"><a name="v:sigmoidCrossEntropyWithLogits" class="def">sigmoidCrossEntropyWithLogits</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: (<a href="../tensorflow-0.1.0.0/TensorFlow-Build.html#t:MonadBuild">MonadBuild</a> m, <a href="../tensorflow-0.1.0.0/TensorFlow-Types.html#t:OneOf">OneOf</a> `[<a href="../base-4.8.2.0/Prelude.html#t:Float">Float</a>, <a href="../base-4.8.2.0/Prelude.html#t:Double">Double</a>]` a, <a href="../tensorflow-0.1.0.0/TensorFlow-Types.html#t:TensorType">TensorType</a> a, <a href="../base-4.8.2.0/Prelude.html#t:Num">Num</a> a)</td><td class="doc empty">&nbsp;</td></tr><tr><td class="src">=&gt; <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Tensor">Tensor</a> <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Value">Value</a> a</td><td class="doc"><p><strong>logits</strong></p></td></tr><tr><td class="src">-&gt; <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Tensor">Tensor</a> <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Value">Value</a> a</td><td class="doc"><p><strong>targets</strong></p></td></tr><tr><td class="src">-&gt; m (<a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Tensor">Tensor</a> <a href="../tensorflow-0.1.0.0/TensorFlow-Tensor.html#t:Value">Value</a> a)</td><td class="doc empty">&nbsp;</td></tr></table></div><div class="doc"><p>Computes sigmoid cross entropy given <code>logits</code>.</p><p>Measures the probability error in discrete classification tasks in which each
 class is independent and not mutually exclusive.  For instance, one could
 perform multilabel classification where a picture can contain both an elephant
 and a dog at the same time.</p><p>For brevity, let `x = logits`, `z = targets`.  The logistic loss is</p><p>z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
      = z * -log(1 <em> (1 + exp(-x))) + (1 - z) * -log(exp(-x) </em> (1 + exp(-x)))
      = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
      = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
      = (1 - z) * x + log(1 + exp(-x))
      = x - x * z + log(1 + exp(-x))</p><p>For x &lt; 0, to avoid overflow in exp(-x), we reformulate the above</p><p>x - x * z + log(1 + exp(-x))
      = log(exp(x)) - x * z + log(1 + exp(-x))
      = - x * z + log(1 + exp(x))</p><p>Hence, to ensure stability and avoid overflow, the implementation uses this
  equivalent formulation</p><p>max(x, 0) - x * z + log(1 + exp(-abs(x)))</p><p><code>logits</code> and <code>targets</code> must have the same type and shape.</p></div></div></div></div><div id="footer"><p>Produced by <a href="http://www.haskell.org/haddock/">Haddock</a> version 2.16.1</p></div></body></html>